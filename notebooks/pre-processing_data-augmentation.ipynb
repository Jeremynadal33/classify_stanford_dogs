{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "pre-processing_data-augmentation.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "built-determination"
      },
      "source": [
        "# This notebook presents the different pre-processing and data augmentation techniques used on the Stanford dataset\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jeremynadal33/classify_stanford_dogs/blob/master/notebooks/pre-processing_data-augmentation.ipynb)\n",
        "\n",
        "\n",
        "There are the different data augmentation steps:\n",
        "* Changing to gray scale\n",
        "* Equalizing the images\n",
        "* Vertical and horizontal flipping\n",
        "* Various rotations\n",
        "* Random zooms (and the check to know wether or not the dog is still on the image\n",
        "* Random translations (same)\n"
      ],
      "id": "built-determination"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHLVfje3P23b"
      },
      "source": [
        "import cv2\n",
        "import os \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np"
      ],
      "id": "oHLVfje3P23b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlyfGqATP9W5"
      },
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  print('Running on CoLab')\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive',force_remount=True)\n",
        "  \n",
        "  root_dir = '/content/gdrive/My Drive/Formation-OC/P6-Images/'\n",
        "  input_dir = root_dir + 'inputs/'\n",
        "  png_dir = root_dir + 'pngs/'\n",
        "\n",
        "  #my script\n",
        "  !ls gdrive/MyDrive/Formation-OC/P6-Images/\n",
        "else:\n",
        "  print('Not running on CoLab')\n",
        "  #my script\n",
        "  root_dir = '/Users/jeremynadal/Documents/Formation OC IML/P6/'\n",
        "  input_dir = root_dir + 'inputs/'\n",
        "  png_dir = root_dir + 'pngs/'\n",
        "  model_dir = root_dir +'models/'"
      ],
      "id": "AlyfGqATP9W5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxPe08CrRcq1"
      },
      "source": [
        "species = os.listdir(input_dir+'sep_images/train/')[:4] #Just 4 to try out\n",
        "base_dir = input_dir+'sep_images/train/'"
      ],
      "id": "jxPe08CrRcq1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_b9WB1iRDI2"
      },
      "source": [
        "## Lets see the effect of whitening and equalization"
      ],
      "id": "6_b9WB1iRDI2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "canadian-weather"
      },
      "source": [
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]).astype(int)\n",
        "\n",
        "def CLAHE_rgb(img): \n",
        "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "\n",
        "  new = np.zeros(img.shape, dtype = int)\n",
        "  new[:,:,0] = clahe.apply(img[:,:,0])\n",
        "  new[:,:,1] = clahe.apply(img[:,:,1])\n",
        "  new[:,:,2] = clahe.apply(img[:,:,2])\n",
        "\n",
        "  return new"
      ],
      "id": "canadian-weather",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgKESPnvRCeH"
      },
      "source": [
        "path_test = base_dir + os.listdir(base_dir)[0]\n",
        "\n",
        "fig, axes = plt.subplots(4, 4, figsize=(20, 15))\n",
        "\n",
        "for specie in range(len(species)):\n",
        "  path = base_dir + species[specie] +'/' + os.listdir(base_dir + species[specie])[0]\n",
        "  img = cv2.imread(path,1)\n",
        "\n",
        "  imgs = [img]\n",
        "  imgs.append( tf.image.per_image_standardization(img) )\n",
        "  imgs.append( equalize_rgb(img) )\n",
        "  imgs.append( CLAHE_rgb(img) ) \n",
        "\n",
        "  for idx in range(len(imgs)):\n",
        "    axes[specie,idx].imshow(imgs[idx])\n",
        "    axes[specie,idx].axis('off')\n",
        "\n",
        "axes[0,0].set_title('Original image')\n",
        "axes[0,1].set_title('Standardised image')\n",
        "axes[0,2].set_title('Equalized image')\n",
        "axes[0,3].set_title('CLAHE image')\n",
        "\n",
        "axes[0,0].set_ylabel(species[0].split('-')[1])\n",
        "axes[0,1].set_ylabel(species[1].split('-')[1])\n",
        "axes[0,2].set_ylabel(species[2].split('-')[1])\n",
        "axes[0,3].set_ylabel(species[3].split('-')[1]) \n",
        "\n",
        "\n",
        "plt.savefig(png_dir+'pre-processing.png')\n",
        "\n",
        "plt.show()"
      ],
      "id": "tgKESPnvRCeH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7YaXDpoTbtA"
      },
      "source": [
        "\n",
        "## Make a new directory to train and put specificaly augmented dataFirst, lets define each function to modify the images. \n",
        "Here, we will :\n",
        "* Flip horizontally \n",
        "* Flip vertically \n",
        "* Horizontal shift\n",
        "* Vertical shift\n",
        "* Rotates the images\n",
        "* Zoom \n",
        "* Modify brightness\n",
        "\n",
        "Make a new directory to train and put specificaly augmented data"
      ],
      "id": "l7YaXDpoTbtA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlZJaCj5TaJB"
      },
      "source": [
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def fill(img, h, w):\n",
        "    img = cv2.resize(img, (h, w), cv2.BORDER_REPLICATE)\n",
        "    return img\n",
        "\n",
        "\n",
        "def shift(img, horizontal = False, vertical = False, ratio=0.0):\n",
        "  \n",
        "  assert not (ratio<-1) or (ratio>1), 'ratio must be between -1 and 1'\n",
        "  assert ((horizontal) or (vertical)) and not ((horizontal) and (vertical)), 'Either horizontal or vertical must be True'\n",
        "  \n",
        "  #ratio = random.uniform(-ratio, ratio)\n",
        "  h, w = img.shape[:2]\n",
        "\n",
        "  if horizontal : \n",
        "    to_shift = w*ratio\n",
        "    if ratio > 0:\n",
        "      img = img[:, :int(w-to_shift), :]\n",
        "    if ratio < 0:\n",
        "      img = img[:, int(-1*to_shift):, :]\n",
        "  elif vertical : \n",
        "    to_shift = h*ratio\n",
        "    if ratio > 0:\n",
        "        img = img[:int(h-to_shift), :, :]\n",
        "    if ratio < 0:\n",
        "        img = img[int(-1*to_shift):, :, :]\n",
        "  \n",
        "  img = fill(img, h, w)\n",
        "  return img\n",
        "\n",
        "\n",
        "def flip(img, vertical = False, horizontal = False ):\n",
        "  assert ((horizontal) or (vertical)) and not ((horizontal) and (vertical)), 'Either horizontal or vertical must be True'\n",
        "\n",
        "  if horizontal : \n",
        "    img = cv2.flip(img, 1)\n",
        "  elif vertical : img = cv2.flip(img, 0)\n",
        "\n",
        "  return img\n",
        "\n",
        "\n",
        "def rotation(img, angle):\n",
        "    #angle = int(random.uniform(-angle, angle))\n",
        "    h, w = img.shape[:2]\n",
        "    M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
        "    img = cv2.warpAffine(img, M, (w, h))\n",
        "\n",
        "    img = fill(img, h, w)\n",
        "    return img\n",
        "\n",
        "\n",
        "def zoom(img, value):\n",
        "    assert not (value<0) or (value>1), 'value must be between -1 and 1'\n",
        "\n",
        "    if value <= 1 : \n",
        "      h, w = img.shape[:2]\n",
        "      h_taken = int(value*h)\n",
        "      w_taken = int(value*w)\n",
        "      h_start = random.randint(0, h-h_taken)\n",
        "      w_start = random.randint(0, w-w_taken)\n",
        "      img = img[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n",
        "      img = fill(img, h, w)\n",
        "    if value > 1 : \n",
        "      h, w = img.shape[:2]\n",
        "      new_h = int(value*h)\n",
        "      new_w = int(value*w)\n",
        "      h_start = new_h - int((h+new_h)/2)\n",
        "      w_start = new_w - int((w+new_w)/2)\n",
        "\n",
        "      new_img = np.zeros((new_h, new_w,3),dtype=int)\n",
        "\n",
        "      new_img[h_start:h_start+h, w_start:w_start+w, :] = img \n",
        "\n",
        "      img = new_img\n",
        "\n",
        "    return img\n",
        "\n",
        "def brightness(img, low=1, high=3):\n",
        "    value = random.uniform(low, high)\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    hsv = np.array(hsv, dtype = np.float64)\n",
        "    hsv[:,:,1] = hsv[:,:,1]*value\n",
        "    hsv[:,:,1][hsv[:,:,1]>255]  = 255\n",
        "    hsv[:,:,2] = hsv[:,:,2]*value \n",
        "    hsv[:,:,2][hsv[:,:,2]>255]  = 255\n",
        "    hsv = np.array(hsv, dtype = np.uint8)\n",
        "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    return img\n",
        "\n",
        "def histogram_equalization(img_in):\n",
        "  # segregate color streams\n",
        "  b,g,r = cv2.split(img_in)\n",
        "  h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
        "  h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
        "  h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
        "  # calculate cdf    \n",
        "  cdf_b = np.cumsum(h_b)  \n",
        "  cdf_g = np.cumsum(h_g)\n",
        "  cdf_r = np.cumsum(h_r)\n",
        "    \n",
        "  # mask all pixels with value=0 and replace it with mean of the pixel values \n",
        "  cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
        "  cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
        "  cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
        "  \n",
        "  cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
        "  cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
        "  cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
        "  cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
        "  cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
        "  cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
        "  # merge the images in the three channels\n",
        "  img_b = cdf_final_b[b]\n",
        "  img_g = cdf_final_g[g]\n",
        "  img_r = cdf_final_r[r]\n",
        "  \n",
        "  img_out = cv2.merge((img_b, img_g, img_r))\n",
        "  # validation\n",
        "  equ_b = cv2.equalizeHist(b)\n",
        "  equ_g = cv2.equalizeHist(g)\n",
        "  equ_r = cv2.equalizeHist(r)\n",
        "  equ = cv2.merge((equ_b, equ_g, equ_r))\n",
        "  \n",
        "  return img_out\n",
        "\n",
        "\n",
        "def handmade_augmentation(input_dir, output_dir):\n",
        "  assert os.path.exists(input_dir), 'input_dir doesnot exist'\n",
        "  assert os.path.exists(output_dir), 'output_dir doesnot exist, please create it first'\n",
        "  \n",
        "  if output_dir[-1]!='/': output_dir+'/'\n",
        "  if input_dir[-1]!='/': input_dir+'/'\n",
        "\n",
        "  species = os.listdir(input_dir) \n",
        "\n",
        "  assert os.path.isdir(input_dir+species[0]), 'input_dir must contain directories of images'\n",
        "\n",
        "  \n",
        "  print('Looking for images and returning 12 times as many images')\n",
        "  for output_fold in os.listdir(output_dir):\n",
        "    os.rmdir(output_dir+output_fold)\n",
        "\n",
        "  for specie in species :\n",
        "    os.mkdir(output_dir+specie)\n",
        "    print('Dealing with ', specie.split('-')[1], '\\nFound {} images'.format(len(os.listdir(input_dir+specie))))\n",
        "\n",
        "    for file in os.listdir(input_dir+specie) :\n",
        "\n",
        "      img = plt.imread(input_dir+specie+'/'+file)\n",
        "      imgs = [img]\n",
        "      imgs.append( shift(img, ratio = 0.25, horizontal= True) ) \n",
        "      imgs.append( shift(img, ratio = 0.25, vertical= True) )\n",
        "\n",
        "      imgs.append( flip(img, horizontal= True) )\n",
        "      imgs.append( flip(img, vertical= True) )\n",
        "\n",
        "      imgs.append( rotation(img, 45) )\n",
        "      imgs.append( rotation(img, -45) )\n",
        "      imgs.append( rotation(img, 135) )\n",
        "\n",
        "      imgs.append( zoom(img, 0.9) )\n",
        "\n",
        "      imgs.append( zoom(img, 1.5) )\n",
        "\n",
        "      imgs.append( brightness(img, 1, 3) )\n",
        "\n",
        "      imgs.append( histogram_equalization(img) )\n",
        "\n",
        "      for idx in range(len(imgs)) :\n",
        "        name = output_dir+specie+'/aug_'+str(file).split('.')[0]+'_'+str(idx)+'.jpg'\n",
        "        cv2.imwrite(name, imgs[idx])\n"
      ],
      "id": "DlZJaCj5TaJB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ORJGfn3UPSk"
      },
      "source": [
        "img_path = baseline_dir+'train/'+os.listdir(baseline_dir+'train/')[3]+'/'+ os.listdir(baseline_dir+'train/'+os.listdir(baseline_dir+'train/')[3])[0]\n",
        "\n",
        "img = plt.imread( img_path, 0  )\n",
        "\n",
        "h, w = img.shape[:2]\n",
        "\n",
        "#img = fill(img, h, w)\n",
        "\n",
        "img_shift_h = shift(img, ratio = 0.25, horizontal= True)\n",
        "img_shift_v = shift(img, ratio = 0.25, vertical= True)\n",
        "\n",
        "img_flip_h = flip(img, horizontal= True)\n",
        "img_flip_v = flip(img, vertical= True)\n",
        "\n",
        "img_rot_1 = rotation(img, 45)\n",
        "img_rot_2 = rotation(img, -45)\n",
        "img_rot_3 = rotation(img, 135)\n",
        "\n",
        "img_zoom_in = zoom(img, 0.9)\n",
        "\n",
        "img_zoom_out = zoom(img, 1.5)\n",
        "\n",
        "img_brightness = brightness(img, 1, 3)\n",
        "\n",
        "img_equalized = histogram_equalization(img)"
      ],
      "id": "-ORJGfn3UPSk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suyu_U9PUPGM"
      },
      "source": [
        "fig, axes = plt.subplots(2, 6, figsize=(20,10), sharex=False)\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "axes[0].imshow(img)\n",
        "axes[0].axis('off')\n",
        "axes[0].set_title('Original img')\n",
        "\n",
        "axes[1].imshow(img_shift_h)\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title('img horizontally shifted')\n",
        "\n",
        "axes[2].imshow(img_shift_v)\n",
        "axes[2].axis('off')\n",
        "axes[2].set_title('img vertically shifted')\n",
        "\n",
        "\n",
        "axes[3].imshow(img_flip_v)\n",
        "axes[3].axis('off')\n",
        "axes[3].set_title('img vertically fliped')\n",
        "\n",
        "axes[4].imshow(img_flip_h)\n",
        "axes[4].axis('off')\n",
        "axes[4].set_title('img horizontal fliped')\n",
        "\n",
        "\n",
        "axes[5].imshow(img_rot_1)\n",
        "axes[5].axis('off')\n",
        "axes[5].set_title('img 45 degres rotated')\n",
        "\n",
        "axes[6].imshow(img_rot_2)\n",
        "axes[6].axis('off')\n",
        "axes[6].set_title('img -45 degres rotated')\n",
        "\n",
        "axes[7].imshow(img_rot_3)\n",
        "axes[7].axis('off')\n",
        "axes[7].set_title('img 135 degres rotated')\n",
        "\n",
        "axes[8].imshow(img_zoom_in)\n",
        "axes[8].axis('off')\n",
        "axes[8].set_title('img zoomed in')\n",
        "\n",
        "axes[9].imshow(img_zoom_out)\n",
        "axes[9].axis('off')\n",
        "axes[9].set_title('img zoomed out')\n",
        "\n",
        "axes[10].imshow(img_brightness)\n",
        "axes[10].axis('off')\n",
        "axes[10].set_title('img increased brightness')\n",
        "\n",
        "axes[11].imshow(img_equalized)\n",
        "axes[11].axis('off')\n",
        "axes[11].set_title('img equalized')\n",
        "\n",
        "plt.savefig(root_dir+'pngs/handmade_augmentation.png')\n",
        "plt.show()"
      ],
      "id": "Suyu_U9PUPGM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd_7R3ASUW82"
      },
      "source": [
        "handmade_augmentation(input_dir= input_dir+'baseline_inputs/train/', output_dir= input_dir+'baseline_inputs/train_aug/')"
      ],
      "id": "qd_7R3ASUW82",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBASU4XoS0pv"
      },
      "source": [
        "## Now lets instanciate an image augmentation object from tf.keras to understand its behavior\n",
        "##Lets build two imagedatagenerator : one will be used for data augmentation later and the other which doesnot do data augmentation. \n",
        "## The latter will be used for both training and validation to create a baseline model"
      ],
      "id": "OBASU4XoS0pv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2alvvftRR1z"
      },
      "source": [
        "def display_aug(generator, img_path, target_size = (150,150), nb_img=4, save = None):\n",
        "    assert nb_img < 7, 'please keep nb_img under 7'\n",
        "    assert len(target_size)==2, 'Target size must be of (height, length)'\n",
        "\n",
        "    img = load_img(img_path, grayscale=False, target_size=target_size)\n",
        "    x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, nb_img, figsize=(int(3*nb_img),int(5*nb_img)), sharex=False)\n",
        "\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    idx = 0\n",
        "    for batch in generator.flow(x, batch_size=1):\n",
        "        axes[idx].imshow(array_to_img(batch[0]))\n",
        "        axes[idx].axis('off')\n",
        "        idx += 1\n",
        "        if idx > nb_img-1:\n",
        "            break\n",
        "    if save : plt.savefig(save)\n",
        "    plt.show()"
      ],
      "id": "a2alvvftRR1z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvcxHnqwRRwU"
      },
      "source": [
        "batch_size = 1\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.1,\n",
        "                                   horizontal_flip=True,\n",
        "                                   vertical_flip = True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "id": "SvcxHnqwRRwU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4VHF9h4RRqc"
      },
      "source": [
        "idx = 0\n",
        "print('Using the augmentation')\n",
        "for specie in baseline_species[:-3]:\n",
        "    display_aug(train_datagen, baseline_dir+'train/'+specie+'/'+os.listdir(baseline_dir+'train/'+specie)[idx], save = png_dir+'image_aug_keras_1.png')\n",
        "    \n",
        "print('Using the no augmentation ')\n",
        "for specie in baseline_species:\n",
        "    display_aug(test_datagen, baseline_dir+'train/'+specie+'/'+os.listdir(baseline_dir+'train/'+specie)[idx])\n",
        "    "
      ],
      "id": "V4VHF9h4RRqc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s645ZtS2RTh3"
      },
      "source": [
        "## Lets create train and validation directories with CLAHE images"
      ],
      "id": "s645ZtS2RTh3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH50AoxLRRl5"
      },
      "source": [
        "def build_clahe_dir(input_dir, output_dir):\n",
        "  assert os.path.exists(input_dir), 'input_dir doesnot exist'\n",
        "  \n",
        "  if output_dir[-1]!='/': output_dir+'/'\n",
        "  if input_dir[-1]!='/': input_dir+'/'\n",
        "\n",
        "  species = os.listdir(input_dir) \n",
        "\n",
        "  assert os.path.isdir(input_dir+species[0]), 'input_dir must contain directories of images'\n",
        "  assert (not os.path.exists(output_dir)) , 'output_dir already exists, consider removing it first'\n",
        "\n",
        "  os.mkdir(output_dir)\n",
        "  print('Looking for images and returning their CLAHE image')\n",
        "\n",
        "  i = 1\n",
        "  for specie in species :\n",
        "    os.mkdir(output_dir+specie)\n",
        "    print('Dealing with ',i,'th specie:', specie.split('-')[1], '\\nFound {} images'.format(len(os.listdir(input_dir+specie))))\n",
        "    i += 1\n",
        "    for file in os.listdir(input_dir+specie) :\n",
        "\n",
        "      img = cv2.imread(input_dir+specie+'/'+file, 1)\n",
        "      new = CLAHE_rgb(img)\n",
        "      name = output_dir+specie+'/clahe_'+str(file).split('.')[0]+'.jpg'\n",
        "      cv2.imwrite(name, new)\n",
        "\n",
        "\n",
        "build_clahe_dir(input_dir+'sep_images/train/',input_dir+'sep_images/train_clahe/')\n",
        "build_clahe_dir(input_dir+'sep_images/validation/',input_dir+'sep_images/validation_clahe/')"
      ],
      "id": "qH50AoxLRRl5",
      "execution_count": null,
      "outputs": []
    }
  ]
}